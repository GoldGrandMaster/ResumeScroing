{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Notebook for Resume NER Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tika\n",
    "tika.initVM()\n",
    "from tika import parser\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def ResumeDataset(train_filepath):\n",
    "    \"\"\"Resumes Dataset\"\"\"\n",
    "    training_data = []\n",
    "    lines = []\n",
    "    \n",
    "    with open(train_filepath,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        text = data['content'].replace(\"\\n\",\" \")\n",
    "        entities = []\n",
    "        data_annotations = data['annotation']\n",
    "        \n",
    "        if data_annotations is not None:\n",
    "            for annotation in data_annotations:\n",
    "                point = annotation['points'][0]\n",
    "                labels = annotation['label']\n",
    "                if not isinstance(labels,list):\n",
    "                    labels = [labels]\n",
    "                \n",
    "                for label in labels:\n",
    "                    point_start = point['start']\n",
    "                    point_end = point['end']\n",
    "                    point_text = point['text']\n",
    "                    \n",
    "                    lstrip_diff = len(point_text)-len(point_text.lstrip())\n",
    "                    rstrip_diff = len(point_text)-len(point_text.rstrip())\n",
    "                    if lstrip_diff!=0:\n",
    "                        point_start = point_start+lstrip_diff\n",
    "                    if rstrip_diff!=0:\n",
    "                        point_end = point_end-rstrip_diff\n",
    "                    entities.append((point_start,point_end+1,label))\n",
    "        training_data.append((text,{\"entities\" : entities}))\n",
    "    return training_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def trim_entity_spans(data:list)->list:\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "    return cleaned_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data = trim_entity_spans(ResumeDataset('dataset/train/Entity Recognition in Resumes.json'))\n",
    "data[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\",\n",
       " {'entities': [[1296, 1622, 'Skills'],\n",
       "   [993, 1154, 'Skills'],\n",
       "   [939, 957, 'College Name'],\n",
       "   [883, 905, 'College Name'],\n",
       "   [856, 860, 'Graduation Year'],\n",
       "   [771, 814, 'College Name'],\n",
       "   [727, 769, 'Designation'],\n",
       "   [407, 416, 'Companies worked at'],\n",
       "   [372, 405, 'Designation'],\n",
       "   [95, 145, 'Email Address'],\n",
       "   [60, 69, 'Location'],\n",
       "   [49, 58, 'Companies worked at'],\n",
       "   [13, 46, 'Designation'],\n",
       "   [0, 12, 'Name']]}]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overlapping entities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def clean_entities(training_data):\n",
    "    \n",
    "    clean_data = []\n",
    "    for text, annotation in training_data:\n",
    "        \n",
    "        entities = annotation.get('entities')\n",
    "        entities_copy = entities.copy()\n",
    "        \n",
    "        # append entity only if it is longer than its overlapping entity\n",
    "        i = 0\n",
    "        for entity in entities_copy:\n",
    "            j = 0\n",
    "            for overlapping_entity in entities_copy:\n",
    "                # Skip self\n",
    "                if i != j:\n",
    "                    e_start, e_end, oe_start, oe_end = entity[0], entity[1], overlapping_entity[0], overlapping_entity[1]\n",
    "                    # Delete any entity that overlaps, keep if longer\n",
    "                    if ((e_start >= oe_start and e_start <= oe_end) \\\n",
    "                    or (e_end <= oe_end and e_end >= oe_start)) \\\n",
    "                    and ((e_end - e_start) <= (oe_end - oe_start)):\n",
    "                        entities.remove(entity)\n",
    "                j += 1\n",
    "            i += 1\n",
    "        clean_data.append((text, {'entities': entities}))\n",
    "                \n",
    "    return clean_data\n",
    "\n",
    "data = clean_entities(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Named Entity Recognition using Spacy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(dataset, test_split):\n",
    "    random.shuffle(dataset)\n",
    "    test_idx = int(test_split*len(dataset))\n",
    "    return dataset[test_idx:],dataset[:test_idx]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train_data,test_data = train_test_split(data, 0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def train():\n",
    "    nlp = spacy.blank('en')\n",
    "    \n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "        \n",
    "    for _,annotations in train_data:\n",
    "        for entity in annotations.get('entities'):\n",
    "            ner.add_label(entity[2])\n",
    "    \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itr in range(10):\n",
    "            print(\"Starting Iteration : \"+str(itr))\n",
    "            random.shuffle(train_data)\n",
    "            losses={}\n",
    "            for text, annotations in train_data:\n",
    "                nlp.update(\n",
    "                    [text],\n",
    "                    [annotations],\n",
    "                    drop=0.2,\n",
    "                    sgd=optimizer,\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(losses)\n",
    "    return nlp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "nlp = train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting Iteration : 0\n",
      "{'ner': 25193.724117724625}\n",
      "Starting Iteration : 1\n",
      "{'ner': 15131.109489998942}\n",
      "Starting Iteration : 2\n",
      "{'ner': 12838.220784650817}\n",
      "Starting Iteration : 3\n",
      "{'ner': 11529.679529788431}\n",
      "Starting Iteration : 4\n",
      "{'ner': 10667.420916098203}\n",
      "Starting Iteration : 5\n",
      "{'ner': 8602.504184416848}\n",
      "Starting Iteration : 6\n",
      "{'ner': 9180.060511769454}\n",
      "Starting Iteration : 7\n",
      "{'ner': 7799.009964035957}\n",
      "Starting Iteration : 8\n",
      "{'ner': 7588.110394783156}\n",
      "Starting Iteration : 9\n",
      "{'ner': 7832.730956936301}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from spacy.gold import GoldParse\n",
    "from itertools import groupby\n",
    "\n",
    "def doc_to_bilou(nlp, text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    tokens = [(tok.text, tok.idx, tok.ent_type_) for tok in doc]\n",
    "    entities = []\n",
    "    for entity, group in groupby(tokens, key=lambda t: t[-1]):\n",
    "        if not entity:\n",
    "            continue\n",
    "        group = list(group)\n",
    "        _, start, _ = group[0]\n",
    "        word, last, _ = group[-1]\n",
    "        end = last + len(word)\n",
    "        \n",
    "        entities.append((\n",
    "                start,\n",
    "                end,\n",
    "                entity\n",
    "            ))\n",
    "\n",
    "    gold = GoldParse(nlp(text), entities = entities)\n",
    "    pred_ents = gold.ner\n",
    "    \n",
    "    return pred_ents\n",
    "\n",
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for text, annots in test_data:\n",
    "    gold = GoldParse(nlp.make_doc(text), entities = annots.get(\"entities\"))\n",
    "    ents = gold.ner\n",
    "    pred_ents = doc_to_bilou(nlp, text)\n",
    "    \n",
    "    y_test.append(ents)\n",
    "    y_pred.append(pred_ents)\n",
    "    \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from itertools import chain\n",
    "\n",
    "def ner_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_)\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset\n",
    "    ), accuracy_score(y_true_combined, y_pred_combined)\n",
    "    \n",
    "report, accuracy = ner_report(y_test, y_pred)\n",
    "print(report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                    -       0.00      0.00      0.00       452\n",
      "       B-College Name       0.62      0.64      0.63        61\n",
      "       I-College Name       0.63      0.55      0.59       135\n",
      "       L-College Name       0.54      0.56      0.55        61\n",
      "       U-College Name       0.00      0.00      0.00         1\n",
      "B-Companies worked at       0.33      0.06      0.10        51\n",
      "I-Companies worked at       0.00      0.00      0.00        59\n",
      "L-Companies worked at       0.33      0.06      0.10        51\n",
      "U-Companies worked at       0.41      0.39      0.40       111\n",
      "             B-Degree       0.70      0.75      0.72        40\n",
      "             I-Degree       0.76      0.83      0.80       125\n",
      "             L-Degree       0.72      0.78      0.75        40\n",
      "             U-Degree       0.69      0.43      0.53        21\n",
      "        B-Designation       0.68      0.51      0.58        88\n",
      "        I-Designation       0.25      0.17      0.20       110\n",
      "        L-Designation       0.59      0.44      0.51        88\n",
      "        U-Designation       1.00      0.33      0.50         3\n",
      "      B-Email Address       0.89      0.67      0.76        12\n",
      "      I-Email Address       0.00      0.00      0.00         2\n",
      "      L-Email Address       0.89      0.67      0.76        12\n",
      "      U-Email Address       0.86      0.96      0.91        26\n",
      "    U-Graduation Year       0.45      0.29      0.35        58\n",
      "           B-Location       0.00      0.00      0.00         6\n",
      "           L-Location       0.00      0.00      0.00         6\n",
      "           U-Location       0.50      0.46      0.48        80\n",
      "               B-Name       1.00      1.00      1.00        44\n",
      "               I-Name       0.00      0.00      0.00         2\n",
      "               L-Name       0.93      0.93      0.93        44\n",
      "                    O       0.94      0.95      0.95     25431\n",
      "             B-Skills       0.42      0.31      0.36        55\n",
      "             I-Skills       0.46      0.60      0.52      1615\n",
      "             L-Skills       0.42      0.31      0.36        55\n",
      "             U-Skills       0.17      0.02      0.04        47\n",
      "            B-UNKNOWN       0.00      0.00      0.00         1\n",
      "            I-UNKNOWN       0.00      0.00      0.00         6\n",
      "            L-UNKNOWN       0.00      0.00      0.00         1\n",
      "B-Years of Experience       0.00      0.00      0.00        12\n",
      "I-Years of Experience       0.00      0.00      0.00         1\n",
      "L-Years of Experience       0.00      0.00      0.00        12\n",
      "U-Years of Experience       0.00      0.00      0.00         1\n",
      "\n",
      "            micro avg       0.89      0.89      0.89     29026\n",
      "            macro avg       0.40      0.34      0.36     29026\n",
      "         weighted avg       0.88      0.89      0.88     29026\n",
      "          samples avg       0.89      0.89      0.89     29026\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8918555777578723\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Model has an F1 Score of 0.89 and an accuracy score of 0.89"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "nlp.to_disk('saved-NER.model')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('P37': conda)"
  },
  "interpreter": {
   "hash": "99224b4fe21c86f432616aa70efdc02870888a2e3e57f0b16a586df12b01d760"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}